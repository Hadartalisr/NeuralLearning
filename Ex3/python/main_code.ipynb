{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47db01dd7a405368",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T23:32:05.899163Z",
     "start_time": "2024-02-18T23:32:05.757789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import loadMNISTLabels, loadMNISTImages, preprocess\n",
    "from copy import deepcopy\n",
    "\n",
    "# from mlp_functions import backprop, test, predict\n",
    "\n",
    "# %% Load images and labels\n",
    "path = '../MNIST_data'\n",
    "def get_path(path, file):\n",
    "    return os.path.join(path, file)\n",
    "\n",
    "ytest = loadMNISTLabels(get_path(path, 't10k-labels.idx1-ubyte'))\n",
    "ytrain = loadMNISTLabels(get_path(path, 'train-labels.idx1-ubyte'))\n",
    "\n",
    "Xtest_raw = loadMNISTImages(get_path(path, 't10k-images.idx3-ubyte'))\n",
    "Xtrain_raw = loadMNISTImages(get_path(path, 'train-images.idx3-ubyte'))\n",
    "\n",
    "print(np.shape(Xtrain_raw))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% display a random image with label:\n",
    "img_index = np.random.randint(np.size(Xtrain_raw, axis=0))\n",
    "img = Xtrain_raw[img_index, :, :]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(str(ytrain[img_index]))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:55:44.637306Z",
     "start_time": "2024-02-18T20:55:44.505113Z"
    }
   },
   "id": "e05031e8573b1b03",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %% preprocess the images (reshape to vectors and subtract mean)\n",
    "Xtrain = preprocess(Xtrain_raw)\n",
    "Xtest = preprocess(Xtest_raw)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T23:32:35.680404Z",
     "start_time": "2024-02-18T23:32:35.545440Z"
    }
   },
   "id": "91e72b492e315e7e",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %% Parameters\n",
    "# The first and last values in layer_sizes should be equal to the input and\n",
    "# output dimensions respectively. Try different values for the layer sizes\n",
    "# inbetween and see how they affect the performance of the network.\n",
    "\n",
    "layers_sizes = [784, 64, 10] # flexible, but must be [784,...,10]\n",
    "epochs = 4      # number of times to repeat over the whole training set\n",
    "eta = 0.1       # learning rate\n",
    "batch_size = 30 # number of samples in each training batch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T22:50:10.777093Z",
     "start_time": "2024-02-18T22:50:10.774537Z"
    }
   },
   "id": "9a8470a75e376d25",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %% Initialize weights\n",
    "# The weights are initialized to normally distributed random values. Note\n",
    "# that we scale them by the previous layer size so that the input to\n",
    "# neurons in different layers will be of similar magnitude.\n",
    "\n",
    "def get_new_weights(layers_sizes):\n",
    "    n_weights = len(layers_sizes)-1\n",
    "    weights = np.zeros((n_weights,), dtype=np.ndarray)\n",
    "    for i in range(n_weights):\n",
    "        weights[i] = np.divide(np.random.standard_normal((layers_sizes[i+1],layers_sizes[i])), layers_sizes[i])\n",
    "    return weights\n",
    "\n",
    "weights = get_new_weights(layers_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T22:50:11.257254Z",
     "start_time": "2024-02-18T22:50:11.246346Z"
    }
   },
   "id": "c7b876590bb3addf",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784)\n",
      "(16, 32)\n",
      "(10, 16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(weights)):\n",
    "    print(np.shape(weights[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T22:39:13.700927Z",
     "start_time": "2024-02-18T22:39:13.691726Z"
    }
   },
   "id": "890daab096622a45",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %% Training\n",
    "N = np.size(Xtrain, axis=0)                        # number of samples\n",
    "n_mbs = np.ceil(N/batch_size).astype(np.int16)    # number of minibatches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2531107eb4c3f2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_activation_function():\n",
    "    return np.tanh\n",
    "\n",
    "\n",
    "def get_activation_function_derivative():\n",
    "    return lambda x: 1 - np.tanh(x)**2\n",
    "\n",
    "\n",
    "def predict(weights, X):\n",
    "    \"\"\"\n",
    "    The function takes as input an array of the weights and a matrix (X)\n",
    "    with images. The outputs should be a vector of the predicted\n",
    "    labels for each image, and a matrix whose columns are the activation of\n",
    "    the last layer for each image.\n",
    "    last_layer_activation should be of size [10 X num_samples]\n",
    "    predicted_labels should be of size [1 X num_samples]\n",
    "    The predicted label should correspond to the index with maximal\n",
    "    activation in the last layer\n",
    "    :param weights: array of the network weights\n",
    "    :param X: samples matrix (match the dimensions to your input)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    activation_function = get_activation_function()\n",
    "    s_layer = X.T\n",
    "    for i in range(0, len(weights)):\n",
    "        _, s_layer = forword_pass_one_layer(weights[i], s_layer, activation_function)\n",
    "    predicted_labels = np.argmax(s_layer, axis=0)\n",
    "    return predicted_labels, s_layer\n",
    "\n",
    "def digit_to_one_hot(y):\n",
    "    one_hot = np.zeros((10, len(y)))\n",
    "    one_hot[y, np.arange(len(y))] = 1\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_to_digit(one_hot):\n",
    "    return np.argmax(one_hot, axis=0)\n",
    "\n",
    "def get_loss(y_hat, y):\n",
    "    return 0.5 * np.mean((np.sum((y_hat - digit_to_one_hot(y))**2, axis=0)))\n",
    "\n",
    "def test(weights, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    This function receives the Network weights, a matrix of samples and\n",
    "    the corresponding labels, and outputs the classification\n",
    "    accuracy and mean loss.\n",
    "    The accuracy is equal to the ratio of correctly labeled images.\n",
    "    The loss is given the square distance of the last layer activation\n",
    "    and the 0-1 representation of the true label\n",
    "    Note that ytest in the MNIST data is given as a vector of labels from 0-9. To calculate the loss you\n",
    "    need to convert it to 0-1 (one-hot) representation with 1 at the position\n",
    "    corresponding to the label and 0 everywhere else (label \"2\" maps to\n",
    "    (0,0,1,0,0,0,0,0,0,0) etc.)\n",
    "    :param weights: array of the network weights\n",
    "    :param Xtest: samples matrix (match the dimensions to your input)\n",
    "    :param ytest: corresponding labels\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    predicted_labels, y_hat = predict(weights, Xtest)\n",
    "    loss = get_loss(y_hat, ytest)\n",
    "    accuracy = np.mean(predicted_labels == ytest)\n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def backprop(weights, X, y):\n",
    "    \"\"\"\n",
    "    This function receives a set of weights, a matrix with images\n",
    "    and the corresponding labels. The output should be an array\n",
    "    with the gradients of the loss with respect to the weights, averaged over\n",
    "    the samples. It should also output the average loss of the samples.\n",
    "    :param weights: an array of length L where the n-th cell contains the\n",
    "    connectivity matrix between layer n-1 and layer n.\n",
    "    :param X: samples matrix (match the dimensions to your input)\n",
    "    :param y: corresponding labels\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    activation_function = get_activation_function()\n",
    "    activation_function_derivative = get_activation_function_derivative()\n",
    "    h_layers, s_layers = forward_pass(weights, X, activation_function)\n",
    "    backword_pass(weights, h_layers, s_layers, y, activation_function_derivative)\n",
    "    print(np.shape(s_layers[-1]))\n",
    "\n",
    "    # return grads, mean_loss\n",
    "\n",
    "def backword_pass(weights, h_layers, s_layers, y, activation_function_derivative):\n",
    "    delta_layers = get_delta_layers(weights, h_layers, s_layers, y, activation_function_derivative)\n",
    "    number_of_samples = len(y)\n",
    "    weights_derivatives = get_gradients_tensor(delta_layers, s_layers, number_of_samples)\n",
    "    return weights_derivatives\n",
    "\n",
    "\n",
    "# tensor[l][miu][i][j] = the derivative of the loss with respect to the weight connecting the i-th neuron in the l+1-th layer\n",
    "# and the j-th neuron in the l-th layer for the miu-th sample in the batch\n",
    "def get_gradients_tensor(delta_layers, s_layers, number_of_samples):\n",
    "    tensor = np.zeros((len(delta_layers),), dtype=np.ndarray)\n",
    "    for i in range(len(delta_layers), 0):\n",
    "        tensor[i] = np.zeros((number_of_samples, len(delta_layers[i]), len(s_layers[i-1])))\n",
    "        for miu in range(number_of_samples):\n",
    "            tensor[i][miu] = np.outer(delta_layers[i][:,miu], s_layers[i][:,miu])\n",
    "    \n",
    "\n",
    "\n",
    "# delta[l][i][miu] = the derivative of the loss with respect to the activation of the i-th neuron in the l-th layer \n",
    "# and the miu-th sample in the batch\n",
    "def get_delta_layers(weights, h_layers, s_layers, y, activation_function_derivative):\n",
    "    delta_layers = np.zeros((len(weights),), dtype=np.ndarray)\n",
    "    for i in range(len(weights)-1, -1, -1):\n",
    "        if i == len(weights)-1:\n",
    "            delta_layers[i] = (s_layers[i] - digit_to_one_hot(y)) * activation_function_derivative(h_layers[i])\n",
    "        else:\n",
    "            delta_layers[i] = np.dot(weights[i+1].T, delta_layers[i+1]) * activation_function_derivative(h_layers[i])\n",
    "    return delta_layers\n",
    "\n",
    "\n",
    "def forword_pass_one_layer(weights, s_layer, activation_function):\n",
    "    next_h_layer =  np.dot(weights, s_layer)\n",
    "    next_s_layer = activation_function(next_h_layer)\n",
    "    return next_h_layer, next_s_layer\n",
    "\n",
    "\n",
    "def forward_pass(weights, X, activation_function):\n",
    "    number_of_layers = len(weights)+1\n",
    "    h_layers = np.zeros((number_of_layers,), dtype=np.ndarray)\n",
    "    s_layers = np.zeros((number_of_layers,), dtype=np.ndarray)\n",
    "        \n",
    "    s_layer =  deepcopy(X.T)\n",
    "    s_layers[0] = s_layer\n",
    "    for i in range(1, number_of_layers):\n",
    "        h_layer, s_layer = forword_pass_one_layer(weights[i], s_layer, activation_function)\n",
    "        h_layers[i] = h_layer\n",
    "        s_layers[i] = s_layer\n",
    "        \n",
    "    return h_layers, s_layers\n",
    "\n",
    "\n",
    "backprop(weights, Xtrain[50:120,:], ytrain[50:120])\n",
    "# print(test(weights, Xtest, ytest))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-19T00:14:58.354441Z"
    }
   },
   "id": "51698301d6550c8b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(70, 784)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[50:120,:].shape\n",
    "# print(test(weights, Xtest, ytest))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T23:34:00.783179Z",
     "start_time": "2024-02-18T23:34:00.773664Z"
    }
   },
   "id": "da44081b71ada8aa",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create vectors to keep track of loss:\n",
    "batch_loss = np.empty((epochs * n_mbs, )) * np.nan\n",
    "test_loss = np.empty((epochs * n_mbs, )) * np.nan\n",
    "test_acc = np.empty((epochs * n_mbs, )) * np.nan\n",
    "iteration = 0\n",
    "for i in range(epochs):\n",
    "    perm = np.random.permutation(N)\n",
    "    for j in range(n_mbs):\n",
    "        idxs = perm[(batch_size * j):min((batch_size * (j+1))-1, N-1)]\n",
    "\n",
    "        # pick a batch of samples:\n",
    "        X_mb = Xtrain[idxs, :]\n",
    "        y_mb = ytrain[idxs]\n",
    "\n",
    "        # compute the gradients:\n",
    "        grads, loss = backprop(weights, X_mb, y_mb)\n",
    "\n",
    "        # keep track of the batch loss\n",
    "        batch_loss[iteration] = loss\n",
    "\n",
    "        # uncomment the next line to keep track of test loss and error.\n",
    "        # test_acc[iteration], test_loss[iteration]= test(weights,Xtest,ytest);\n",
    "        # Note: evaluating the test_loss for each batch will slow down\n",
    "        # computation. If it is too slow you can instead evaluate the test\n",
    "        # loss at a lower frequency (once every 10 batches or so...)\n",
    "\n",
    "        # update the weights:\n",
    "        for k in range(len(weights)):\n",
    "            weights[k] = weights[k] - eta * grads[k]\n",
    "\n",
    "        iteration = iteration + 1  # counts the number of updates\n",
    "\n",
    "    acc, loss = test(weights, Xtest, ytest)\n",
    "    print('Done epoch %d, test accuracy: %f\\n' % (i, acc))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b263caa08f72d31",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %% Plot some results\n",
    "# Example plot of the learning curve\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(batch_loss, 'r-', label='Training loss')\n",
    "ax1.plot(test_loss, 'k-', label='Test loss')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(test_acc, label='Test accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "fig.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167bf739f376c66a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m Xtest_raw \u001B[38;5;241m=\u001B[39m loadMNISTImages(get_path(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt10k-images.idx3-ubyte\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     18\u001B[0m Xtrain_raw \u001B[38;5;241m=\u001B[39m loadMNISTImages(get_path(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain-images.idx3-ubyte\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(np\u001B[38;5;241m.\u001B[39mshape(Xtrain_raw))\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# %% display a random image with label:\u001B[39;00m\n\u001B[1;32m     23\u001B[0m img_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39msize(Xtrain_raw, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "Cell \u001B[0;32mIn[2], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m Xtest_raw \u001B[38;5;241m=\u001B[39m loadMNISTImages(get_path(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt10k-images.idx3-ubyte\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     18\u001B[0m Xtrain_raw \u001B[38;5;241m=\u001B[39m loadMNISTImages(get_path(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain-images.idx3-ubyte\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(np\u001B[38;5;241m.\u001B[39mshape(Xtrain_raw))\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# %% display a random image with label:\u001B[39;00m\n\u001B[1;32m     23\u001B[0m img_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39msize(Xtrain_raw, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# %% Display 10 misclassifications with highest loss\n",
    "# Example showing some misclassifications\n",
    "yhat, output = predict(weights, Xtest)\n",
    "t = np.zeros((10,len(ytest)))\n",
    "for i in range(len(ytest)):\n",
    "    t[ytest[i], i] = 1\n",
    "\n",
    "test_losses = sum((output-t)**2)\n",
    "sorted_index = np.argsort(-test_losses) # - for descending\n",
    "idxs = sorted_index[:10]\n",
    "\n",
    "plt.figure()\n",
    "for k in range(10):\n",
    "    ax = plt.subplot(2, 5, k+1)\n",
    "    x = Xtest_raw[idxs[k], :, :]\n",
    "    ax.imshow(x)\n",
    "    ax.set_xlabel('True label: %d\\n Prediction: %d' % (ytest[idxs[k]], yhat[idxs[k]]), fontsize=12)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:54:17.679939Z",
     "start_time": "2024-02-18T20:53:25.426041Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
